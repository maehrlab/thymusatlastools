
---
title: "Cleaning the DGE Data"
author: "Eric Kernfeld"
date: "September 7, 2016"
output: html_document
---

###Pseudotime analysis

```{r}
#' Run Monocle (or simpler PCA-based pseudotime) on a Seurat object, transferring input and output automatically to and from a CellDataSet object.
#'
#' @param dge Seurat object
#' @param results_path Where to save tables and plots
#' @param earliest_day Numeric. Used to root the Monocle trajectory; gets compared to `FetchData(dge, "eday")[[1]]` via `==`.
#' @param mp Passed to call_monocle_on_seurat as monocle_params arg.
#' @param ... Additional parameters passed to call_monocle_on_seurat.
#'
#' @details This function will look for interesting genes of different types and save a ton of plots.
#' The statistical inference is outsourced to Monocle via call_monocle_on_seurat (or Seurat via pc_as_pt).
#'
master_pt = function( dge, results_path, method = "monocle", earliest_day = NULL,
                      mp = list( reset_var_genes       = T, 
                                 log_scale_expr_thresh = 0.1,
                                 excess_disp           = 1,
                                 num_mature_types      = NULL,
                                 reduction_method      = "DDRTree" ), ...  ){
  # # Run monocle & transfer results
  dir.create.nice( results_path )
  if( method=="PCA" ){
    dge = pc_as_pt( dge )$dge
  } else if (method=="DPT") {
    dm = destiny::DiffusionMap( data = t( as.matrix( dge@data ) ) )
    dpt_out = destiny::DPT( dm )
    dge = add_pseudotime_to_seurat( dge, pt_obj = dpt_out, pt_method = "dpt" )
    saveRDS( dpt_out, file.path( results_path, "dpt_out.data" ) )
  } else {
    mobj = call_monocle_on_seurat( dge, results_path, monocle_params = mp, earliest_day = earliest_day, ... )
    dge = add_pseudotime_to_seurat( dge, pt_obj = mobj )
    saveRDS( mobj, file.path( results_path, "mobj_TECs.data" ) )
  }
  saveRDS( dge,  file.path( results_path, "dge_TECs.data" ) )
  
  # # Plot default genes
  bv = paste0("branch_viz_", 1:2)
  misc_summary_info ( dge, results_path )
  # save_feature_plots( dge, results_path )
  if( method!="PCA" ){
    misc_summary_info ( dge, results_path, axes = bv, axes_description = "monocle_branch_viz" )
    save_feature_plots( dge, results_path, axes = bv, axes_description = "monocle_branch_viz" )
  }
  save_feature_plots( dge, results_path, do_time_series = T  )
  
  return( dge )
}


#' Take a principal component (first by default) and return a list of results gained by interpreting that PC as a pseudotime axis.
#'
#' @param dge: Seurat object to be used. Should have variable genes and PCA fields already filled in. 
#' Jackstraw and t-SNE are optional but preferred.
#' @param orient_var: pseudotime is flipped to correlate positively with this. Anything available 
#' from `Seurat::FetchData(dge, orient_var)` is fair game... as long as it's numeric.
#' @param pc.use: which principal component to take
#' 
#' @value List with named elements:
#' `$dge`: Seurat object with a `pseudotime` metadatum filled in
#' `$gene_corrs`: dataframe with genes ordered by correlation with pseudotime.
#'    Columns are `gene`, `corr`, and (if available from Jackstraw) `p_value`.
pc_as_pt = function( dge, pc.use = 1, orient_var = "eday" ){
  
  # # Construct pseudotime
  pt = Seurat::FetchData(dge, paste0("PC", pc.use)) %>% vectorize_preserving_rownames
  
  # # Get correlations with genes and sort through them
  dge = ProjectPCA( dge, do.print = F )
  gene_corrs = dge@pca.x.full[, "PC1", drop = F] %>% vectorize_preserving_rownames %>% sort
  gene_corrs = data.frame( gene = names(gene_corrs), 
                           corr = gene_corrs ) 
  if( prod( dim( dge@jackStraw.empP.full ) ) > 0 ){
    # Need to index by gene because of earlier sorting
    gene_corrs$p_value = dge@jackStraw.empP.full[gene_corrs$gene, "PC1"]
  } 
  rownames(gene_corrs) = gene_corrs$gene
  
  # # Flip everything if necessary
  wrong_way = cor( pt, Seurat::FetchData( dge, orient_var )[[1]] ) < 0
  if( wrong_way ){ orient = function(x) -x } else { orient = function(x) x }
  pt                  %<>% orient
  dge@pca.rot   [, 1] %<>% orient
  dge@pca.x     [, 1] %<>% orient
  dge@pca.x.full[, 1] %<>% orient
  gene_corrs$corr %<>% orient
  
  # # Add pt as metadata and return
  dge = Seurat::AddMetaData( dge, pt, "pseudotime" )
  return( list( dge = dge, gene_corrs = gene_corrs ) )
}

#' Characterize genes by behavior over pseudotime, returning cluster assignments and effect sizes. 
#' 
#' @param dge should be a seurat object with a field "pseudotime". 
#' The field `dge@data` is accessed for expression levels -- for Eric's objects, the units will be log2(1+CP10K).
#' @param results_path is a character vector showing where to dump the output.
#' @param num_periods_initial_screen Cells are partitioned into this many pseudotime periods (equal number of cells in each).
#' They get averaged and each gene's "effect size" is the largest minus the smallest average.
#' @param prop_genes_keep Genes are ranked by effect size and the top prop_genes_keep*100% are sent into smoothers and kmeans.
#' @param abcissae_kmeans Gene expression is fed into k-means as a series of predictions at successive time points.
#' The arguments says how many time points to predict and feed in (if length one) or what time points (if longer).
#' @param num_clusters Genes are partitioned into this many modules. If NULL (default) the value is selected via the gap statistics and their SEs using the method in the original gap statistic paper.
#' 
#'       Tibshirani, R., Walther, G. and Hastie, T. (2001). Estimating the number 
#'       of data clusters via the Gap statistic. Journal of the Royal Statistical Society B, 63, 411â€“423.
#'                                 
#' There's one adjustment: this function will never use just one cluster. It will issue a warning and use 2.
#'
#' @value A list with elements:
#'
#' - dge: the Seurat object
#' - gene_stats: genes with effect sizes and cluster labels.
#' - smoothers: fitted regression models, one for each gene.
#' - cluster_mod: output from stats::kmeans 
#' - gap_stats: output from cluster::clusGap
#'
#' @details This function helps explore gene dynamics over pseudotime. It goes through three main steps:
#'
#' - find genes that respond strongly to pseudotime.
#' - smooth those genes' expression to form an overall pseudotime trend.
#' - cluster genes based on smoothed expression patterns that have been shifted/scaled to the unit interval.
#'
smooth_and_cluster_genes = function( dge, results_path, 
                                     num_periods_initial_screen = 20, 
                                     prop_genes_keep = 0.1,
                                     abcissae_kmeans = 20,
                                     num_clusters = NULL ){
  
  # # Get data and average within epochs
  dir.create.nice( results_path )
  cat("Screening out bottom", 100*(1-prop_genes_keep), 
      "%, ranked by max minus min of average expression within", num_periods_initial_screen, "epochs ...\n")
  cell_data = Seurat::FetchData( dge , "pseudotime" )
  nbreaks = num_periods_initial_screen+1
  breaks = quantile(cell_data$pseudotime, probs = (1:nbreaks - 0.5)/nbreaks)
  cell_data$period = cut( x = cell_data$pseudotime, 
                          breaks = breaks, 
                          labels = as.character( 1:num_periods_initial_screen ),
                          include.lowest = T, ordered_result = T)
  dge = Seurat::AddMetaData( dge, cell_data[, "period"] %>% matrixify_preserving_rownames, "period" )
  genes_by_period = t( aggregate.nice( t(dge@data), by = cell_data$period, FUN = mean ) )
  nonzero = apply( genes_by_period, 1, function(x) any(x>0) )
  genes_by_period = genes_by_period[nonzero, ]
  min2max = function(x) (max(x) - min(x))
  effect_size = apply( genes_by_period, 1, min2max )
  cutoff = quantile( effect_size, 1-prop_genes_keep )
  genes_included = names(which(effect_size > cutoff )) 
  {
    pdf( file.path( results_path, "effect_sizes.pdf" ) )
    hist( effect_size, main = paste0("Max minus min average over ", num_periods_initial_screen, " periods"), breaks = 50 )
    abline( v = cutoff )
    dev.off()
  }
  
  cat("Smoothing gene expression over pseudotime...\n")
  pt_data = FetchData( dge, c( "pseudotime", genes_included ) )
  s = mgcv:::s
  fast_smooth = function( gene ) { 
    gene = pt_data[[gene]] 
    pseudotime = pt_data[["pseudotime"]]
    mgcv::gam( gene ~ s( pseudotime ), family = mgcv::nb() )
  }
  smoothers = lapply( genes_included, fast_smooth )
  names( smoothers ) = genes_included
  
  # # Generate kmeans features
  if( length( abcissae_kmeans ) == 0 ) { abcissae_kmeans = 20 }
  if( length( abcissae_kmeans ) == 1 ) {
    abcissae_kmeans = quantile(cell_data$pseudotime, (1:abcissae_kmeans - 0.5)/abcissae_kmeans )
  }
  kmeans_features = sapply( smoothers, predict, type = "response", 
                            newdata = data.frame( pseudotime = abcissae_kmeans ) )
  kmeans_features = t(kmeans_features)
  #rescale each gene to the unit interval
  kmeans_features = apply( kmeans_features, MARGIN = 1, FUN = function( x ) (x - min(x)) ) %>% t
  kmeans_features = apply( kmeans_features, MARGIN = 1, FUN = div_by_max ) %>% t
  atae(ncol(kmeans_features), length(abcissae_kmeans))
  atae(nrow(kmeans_features), length(genes_included))
  rownames(kmeans_features) = genes_included
  
  cat("  Calculating gap statistics... \n")
  gap_stats = cluster::clusGap( x = kmeans_features, FUNcluster = kmeans, K.max = 25, spaceH0 = "scaledPCA", 
                                iter.max = length(abcissae_kmeans) * 2 )
  {
    pdf( file.path( results_path, "gap_stats.pdf" ) )
    plot( gap_stats )
    dev.off()
  }
  if( is.null( num_clusters ) ) {
    num_clusters = cluster::maxSE(gap_stats$Tab[, 3], gap_stats$Tab[, 4], "Tibs2001SEmax") 
    if( num_clusters == 1 ){
      warning("Based on gap statistics, Tibshirani et alii suggest one cluster, but that's boring so I'll use two.")
      num_clusters = 2
    }
  }
  cat("  Continuing with ", num_clusters,  " clusters.\n")
  cluster_mod = kmeans( kmeans_features, centers = num_clusters, iter.max = 500 )
  
  # Reorder clusters by hierarchical clustering 
  peak_position = apply( cluster_mod$centers, 1, function( x ) mean( which( x > 0.75 ) ) )
  my_rf = function(hc) as.hclust(stats::reorder(as.dendrogram(hc), order(peak_position)))
  converter = dendrogram_merge_points( X = cluster_mod$centers, num_desired = 3,
                                       REORDER_FUN = my_rf,
                                       PLOT_FUN = function(...){ }, # skip plotting
                                       results_path = results_path, return_hc = F )
  hc        = dendrogram_merge_points( X = cluster_mod$centers, num_desired = 3, 
                                       REORDER_FUN = my_rf,
                                       PLOT_FUN = function(...){ }, # skip plotting
                                       results_path = results_path, return_hc = T )
  preferred_ordering = hc$order
  # image(cluster_mod$centers[preferred_ordering, ]) # Sneak peek for development
  
  old_given_new = preferred_ordering
  new_given_old = function( k ){ which(k==old_given_new)}
  cluster_mod$cluster  = sapply( cluster_mod$cluster, new_given_old )
  cluster_mod$centers  = cluster_mod$centers [old_given_new, ]
  cluster_mod$withinss = cluster_mod$withinss[old_given_new]
  cluster_mod$size     = cluster_mod$size    [old_given_new]
  rownames(cluster_mod$centers) = NULL
  
  # # Assemble data for export
  cat("Exporting cluster assignments and effect sizes for genes under study... \n")
  to_return = data.frame( gene = genes_included,
                          max_log2_fc = effect_size[genes_included], 
                          cluster = cluster_mod$cluster[genes_included] )
  to_return = to_return[order( to_return$cluster, -to_return$max_log2_fc ), ]
  write.table( to_return, file.path(results_path, "gene_pt_dependence_stats.txt"), 
               sep = "\t", quote = F, row.names = F, col.names = T)
  
  cat("Done.\n")
  return( list( dge = dge,
                # smoothing/filtering
                gene_stats = to_return,
                smoothers = smoothers, 
                # clustering
                abcissae_kmeans = abcissae_kmeans,
                kmeans_features = kmeans_features,
                cluster_mod = cluster_mod,
                gap_stats = gap_stats, 
                # dendrogram of cluster means
                converter = converter, 
                hc = hc ) )
}

#' Draw overlaid line plots of gene clusters from output of `smooth_and_cluster_genes`.
#'
#' @param facet_ncol For resulting facet plots, number of columns. 
facet_plot_gene_clusters = function( dge, results_path, 
                                     cluster_mod, 
                                     kmeans_features,
                                     abcissae_kmeans, 
                                     facet_ncol = NULL ){
  cluster_mod$cluster = factor( cluster_mod$cluster )
  num_clusters = length(levels(cluster_mod$cluster))
  centers = aggregate.nice( kmeans_features, by = cluster_mod$cluster, FUN = mean )
  data_wide = data.frame( rbind( centers, kmeans_features ) )
  data_wide$is_center = F; data_wide$is_center[1:num_clusters] = T
  data_wide$cluster = c( levels(cluster_mod$cluster), as.character( cluster_mod$cluster ) )
  data_wide$gene = rownames( data_wide )
  
  data_long = melt( data_wide, id.vars = c( "is_center", "cluster", "gene" ))
  data_long$unit_scaled_expression = data_long$value
  data_long$pseudotime = abcissae_kmeans[ data_long$variable ]
  data_long$cluster %<>% factor(levels = rev(sort(unique(data_long$cluster))), ordered = T)
  p_faceted_clusters = ggplot() + ggtitle( "Major gene clusters" ) +
    geom_line( data = subset( data_long, !is_center), alpha = 0.6,
               aes( x = pseudotime, y = unit_scaled_expression, group = gene, colour = cluster ) ) +
    geom_line( data = subset( data_long, is_center), alpha = 1, colour = "black",
               aes( x = pseudotime, y = unit_scaled_expression, group = gene  ) ) +
    facet_wrap( ~cluster, ncol = facet_ncol ) + 
    theme(strip.background = element_blank(), legend.position = "none") +
    ylab("Unit-scaled expression") + 
    scale_colour_grey()

  ggsave( filename = file.path(results_path, "faceted_gene_clusters.pdf"), 
          p_faceted_clusters, 
          width = 5, height = 6 )
  return( p_faceted_clusters )
}

#' Draw heatmaps of gene clusters from output of `smooth_and_cluster_genes`.
#'
#' @param dge Seurat object with raw data and pseudotime metadata used to train smoothers. 
#' If metadata `simple_branch` is present, function is hardwired to look for "mTEC", "cTEC", "branchpoint", and "progenitor"
#' and make a heatmap similar to figure 2 in http://dx.doi.org/10.1101/122531. 
#' @param results_path Where to save plots and files.
#' @param cluster_mod K-means output with cluster labels for the genes in `smoothers` and also with cluster centers.
#' @param smoothers List of regression models for the genes in `cluster_mod` and `gene_stats`.
#' @param gap_size White bars separating clusters are formed by adding fake genes. gap_size is how many fake genes per bar.
#' @param genes_use 
#' @param genes_to_label
heatmap_gene_clusters = function( dge, results_path, 
                                  cluster_mod, 
                                  smoothers,
                                  gap_size = NULL,
                                  genes_use = NULL,
                                  genes_to_label = NULL ){  
  cell_data = dge %>% FetchData("pseudotime")
  num_clusters = length( unique( cluster_mod$cluster ) )
  atae( names( smoothers ), names(cluster_mod$cluster) )
  
  if( is.null( genes_use ) ){
    genes_use = names(cluster_mod$cluster)
  } else {
    cluster_mod$cluster = cluster_mod$cluster[genes_use]
    smoothers = smoothers[genes_use]
  }
  
  # # set up wide-format data
  if( "simple_branch" %in% AvailableData( dge ) ){
    abcissae_heatmap = FetchData(dge, "pseudotime")[[1]] 
    #avoids exact duplicates; need to use these as dimnames
    abcissae_heatmap = abcissae_heatmap + rnorm( n = length(abcissae_heatmap), mean = 0, sd = 1e-8 )
    abcissae_heatmap %<>% sort
  } else {
    abcissae_heatmap = seq( min(cell_data$pseudotime), max(cell_data$pseudotime), length.out = 100 )
  }
  data_wide_heat = sapply( smoothers, predict, type = "response", 
                           newdata = data.frame( pseudotime = abcissae_heatmap ) ) 
  rownames(data_wide_heat) = abcissae_heatmap
  peak_expression = apply( data_wide_heat, 2, which.max ); names(peak_expression) = names(smoothers)
  data_wide_heat = apply(data_wide_heat, 2, standardize) %>% t %>% as.data.frame
  data_wide_heat$gene = names(smoothers)
  data_wide_heat$cluster = cluster_mod$cluster

  # # Add bars between clusters by adding dummy genes ranked last in each cluster
  if( is.null(gap_size) ){
    gap_size = ifelse( length(genes_use) < 50, 0, ceiling( length(smoothers) / 100 ) )
  }
  scaffold = rep( 1:nrow(cluster_mod$centers), each = gap_size )
  if( gap_size > 0 ){
    dummy_genes = matrix( NA, 
                          ncol = length( abcissae_heatmap ), 
                          nrow = length( scaffold ) ) %>% as.data.frame
    dummy_genes$gene = paste0("DUMMY_GENE_", scaffold ) %>% make.unique
    dummy_genes$cluster =                    scaffold
    colnames(dummy_genes) = colnames(data_wide_heat)
    data_wide_heat = rbind( data_wide_heat, dummy_genes )
    peak_expression = c( peak_expression, rep( Inf, length(scaffold) ) ) #used for ranking
  }
  
  # # Add vertical bar for branching heatmap
  if( "simple_branch" %in% AvailableData( dge ) ){
    pt_by_branch = aggregate.nice( x =  FetchData(dge, "pseudotime"), 
                                   by = FetchData(dge, "simple_branch"), 
                                   FUN = mean )
    atae( pt_by_branch["progenitor", ], 0, tol = 1e-8 )
    atae( pt_by_branch["branchpoint", ], 0, tol = 1e-8 )
    atat( pt_by_branch["mTEC", ] < 0 )
    atat( pt_by_branch["cTEC", ] > 0 )
    branch_counts = FetchData(dge, "simple_branch") %>% table
    boundary = branch_counts["mTEC"] + branch_counts["progenitor"] / 2 + branch_counts["branchpoint"] / 2
    dummy_cells = matrix(NA, nrow = nrow( data_wide_heat ), ncol = ncol( data_wide_heat )/40 )
    middle_pt = abcissae_heatmap[boundary + 0:1 ]
    colnames(dummy_cells) = seq( max(middle_pt) + 1e-8, 
                                 min(middle_pt) - 1e-8, length.out = ncol( dummy_cells ) )
    is_left = 1:ncol(data_wide_heat) < boundary
    data_wide_heat = cbind( data_wide_heat[,  is_left],
                            dummy_cells,
                            data_wide_heat[, !is_left] )
  }
  
  # # Melt data and order rows
  data_wide_heat$gene = factor( data_wide_heat$gene, 
                                levels = data_wide_heat$gene[order(data_wide_heat$cluster, -peak_expression)] , 
                                ordered = T)
  data_wide_heat = data_wide_heat[order(data_wide_heat$gene), ]
  data_long_heat = melt(data_wide_heat, id.vars = c("gene", "cluster"))
  data_long_heat %<>% rename( c("variable" = "pseudotime", "value" = "rel_log_expr") )

  # # Smoothed heatmap
  p_heat_clusters = ggplot(data = data_long_heat ) + 
    ggtitle( "Genes clustered by temporal expression pattern" ) +
    geom_raster( aes( x = pseudotime, y = gene, fill = rel_log_expr ), 
                 interpolate = T ) +
    scale_fill_gradientn( colors = blue_gray_red, na.value="white" ) + 
    theme(axis.line = element_blank(), axis.ticks = element_blank(), axis.text.x=element_blank()) 
  
  # # Label selected genes
  rest = setdiff( data_wide_heat$gene, genes_to_label )
  ylabels = c( genes_to_label, rep("", length(rest))  )
  names(ylabels) = c( genes_to_label, rest )
  p_heat_clusters = p_heat_clusters + 
    scale_y_discrete( labels = ylabels ) + labs( y = "Genes" ) 

  # # X axis is either by cells (branching) or by pseudotime (not branching).
  if( "simple_branch" %in% AvailableData( dge ) ){
    p_heat_clusters = p_heat_clusters + xlab("Cells")  
  } else {
    p_heat_clusters = p_heat_clusters + xlab("Pseudotime")
  }
  
  # # Add cluster colorbar
  boundary_genes = which(1==diff(sort(data_wide_heat$cluster)))
  boundary_genes = c(0, boundary_genes, length( data_wide_heat$gene ) ) 
  right_edge = max(as.numeric(data_long_heat$pseudotime))
  left_edge  = min(as.numeric(data_long_heat$pseudotime))
  for( i in 1:num_clusters ){
    p_heat_clusters = p_heat_clusters +
      annotate( "rect", 
                xmin = left_edge - 4 * (right_edge - left_edge) / 100,
                xmax = left_edge -     (right_edge - left_edge) / 100,
                ymin = boundary_genes[i  ] + gap_size,
                ymax = boundary_genes[i+1],
                fill = scales::hue_pal()(num_clusters)[i]) + 
      annotate( "text", 
                x = left_edge - 8 * (right_edge - left_edge) / 100, 
                y = (boundary_genes[i  ] + gap_size + boundary_genes[i+1]) / 2, 
                label = i) 
    
  }
  
  # # Add cell types
  branch_colors = c(scales::hue_pal()(2), "purple", "gray" )
  names(branch_colors) = c("mTEC", "cTEC", "progenitor", "branchpoint" )
  if( "simple_branch" %in% AvailableData( dge ) ){
    X = FetchData(dge, c("simple_branch", "pseudotime")) 
    X = X[order(X$pseudotime), ]
    X = X[["simple_branch"]] %>% as.character %>% rle #run-length encoding keeps from overwhelming ggplot
    X$positions = c(0, cumsum(X$lengths) )
    X$positions %<>% div_by_max
    X$positions = X$positions*right_edge
    for( i in 1:length(X$values) ){
      cell_label_data = 
        data.frame( 
          xmin = X$positions[i], 
          xmax = X$positions[i+1], 
          ymin = 2*ceiling( length(smoothers) / 100 ),
          ymax = 0 )
      p_heat_clusters = p_heat_clusters + 
        geom_rect( data = cell_label_data,
                   aes( xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax ), 
                   fill = branch_colors[X$values[i]] ) 
      
      dummy_cells_pseudotime = as.numeric(colnames(dummy_cells)) * right_edge / max(X$positions)
      p_heat_clusters = p_heat_clusters + 
        annotate( geom = "rect", fill = "white", 
                  xmin = min( dummy_cells_pseudotime ), 
                  xmax = max( dummy_cells_pseudotime ), 
                  ymin = 2*ceiling( length(smoothers) / 100 ), 
                  ymax = 0 ) 
    }                
  }

  ggsave( filename = file.path(results_path, "heatmapped_gene_clusters.png"), 
          p_heat_clusters, width = 6, height = 7 )
  ggsave( filename = file.path(results_path, "heatmapped_gene_clusters.pdf"), 
          p_heat_clusters, width = 6, height = 7 )
  return( p_heat_clusters )
}

#' Plot a dendrogram, labeling merges given by `converter` with colored rectangles. 
#'
#' @details If converter is c("a", "a", "b", "c"), you get edges labeled as a 
#' four-colour muted rainbow next to a grayscale with light, light, medium, and dark.
#' This is to convey that the first two tips have been somehow grouped.
 plot_dendro_with_rect = function( hc, converter, main = "Dendrogram" ){
    p = ggdendro::ggdendrogram(hc)
    p = p + annotate( geom = "tile", x = 1:length(hc$order), 
                      y = -2, 
                      fill = scales::hue_pal()(length(hc$order)) ) 
    p = p + annotate( geom = "tile", x = 1:length(hc$order), 
                      y = -1, 
                      fill = scales::grey_pal()(3)[factor(converter[hc$order])] ) 
    p = p + ggtitle(main)
    print(p)
    return(p)
  }
#' Plot a dendrogram and also cut it to merge input into `num_desired` groups.
#'
dendrogram_merge_points = function( X, num_desired, results_path, 
                                    FUN = function(x) hclust(dist(x), method = "ward.D2"), 
                                    REORDER_FUN = function(hc) as.hclust(stats::reorder(as.dendrogram(hc), 1:nrow(X))), 
                                    PLOT_FUN = plot_dendro_with_rect,
                                    CUT_FUN = stats::cutree,
                                    main = "Dendrogram",
                                    return_hc = F,
                                    ... ){
  hc = FUN( X, ... )
  hc = REORDER_FUN( hc )
  converter = CUT_FUN(hc, num_desired)
  converter = setNames( letters[converter], names(converter) )
  atae(as.character(hc$labels), names(converter))
  hc$labels = paste0( hc$labels, " (", converter[hc$labels], ")" ) 
  {
    pdf( file.path( results_path, paste0( main, ".pdf" ) ) )
    PLOT_FUN( hc, converter, main = main )
    dev.off()
  }
  PLOT_FUN( hc, converter, main = main )
  
  if(return_hc){
    return( hc )
  }
  return( converter )
}

```

```{r}
#' Extract data from a Seurat object and run Monocle, returning a Monocle object.
#'
#'
call_monocle_on_seurat = function( dge, results_path, monocle_params, earliest_day = NULL ){
  
  attach( monocle_params )

  # # Make (m)onocle (obj)ect
  raw_dge = deseuratify_raw_data( dge )
  geneInfo = data.frame( dge@mean.var[rownames(raw_dge), ] )
  geneInfo$gene = rownames(geneInfo)
  pd = new("AnnotatedDataFrame", data = dge@data.info[colnames(raw_dge), ])
  fd = new("AnnotatedDataFrame", data = geneInfo)
  mobj = newCellDataSet( as.matrix( raw_dge ), 
                         phenoData = pd, 
                         featureData=fd,
                         lowerDetectionLimit=1,
                         expressionFamily=negbinomial.size( ) )

  # # Select variable genes or get from Seurat object
  mobj = detectGenes( mobj, min_expr = 0 )
  mobj = estimateSizeFactors( mobj )
  mobj = estimateDispersions( mobj )
  if(reset_var_genes){
    disp_table = dispersionTable( mobj )
    ordering_genes = subset(disp_table,
                            ( mean_expression >= log_scale_expr_thresh ) & 
                              ( dispersion_empirical >= excess_disp * dispersion_fit ) )[["gene_id"]]
    cc_genes_go = read.table(file.path(PATH_TO_TABLES, "ms_cellcycleGO0007049.txt"),   sep="\t")
    cc_genes_macosko = get_macosko_cc_genes()
    cc_genes_all = Reduce(union, cc_genes_macosko) %>% union(., cc_genes_go)
    ordering_genes %<>% as.character %>% setdiff( cc_genes_all )
    expressed_genes = row.names(subset(fData(mobj), num_cells_expressed >= 10))
    ordering_genes = intersect(expressed_genes,ordering_genes)
    mobj = setOrderingFilter(mobj,ordering_genes)
  } else {
    mobj = setOrderingFilter(mobj, dge@var.genes )
  }

  # # Save variable genes and parameters
  vgsrp = file.path( results_path, "var_gene_select" )
  dir.create.nice( vgsrp )
  gd = mobj@featureData@data
  var_genes = gd$gene[gd$use_for_ordering]
  cell_markers = get_rene_markers()
  variable_cell_markers = intersect( Capitalize(cell_markers$marker), Capitalize(as.character(var_genes)) )
  variable_cell_markers = c(paste0(length(variable_cell_markers), "total"), variable_cell_markers)
  text2file( file.path( vgsrp, "markers_among_variable_genes_monocle.txt" ), variable_cell_markers )
  totalstring = paste(length(as.character(var_genes)), "total")
  var_genes = c(totalstring, as.character(var_genes))
  text2file(file.path(vgsrp, "variable_genes_monocle.txt"), var_genes)
  vsp        = c( excess_disp,   log_scale_expr_thresh)
  names(vsp) = c("excess_disp", "log_scale_expr_thresh")
  text2file(file.path(vgsrp, "var_gene_selection_params_monocle.txt"), collapse_by_name(vsp))
  
  
  # # Do Monocle dimension reduction, correcting for cell cycle but not batch effects 
  # # (For us, batch effects are often completely nested inside of embryonic day, 
  # # so we can't adjust for them without removing the temporal signal.)
  form_str = paste0( "~", paste0( CC_PHASES, collapse = " + " ) )
  mobj = reduceDimension(mobj,residualModelFormulaStr=form_str,pseudo_expr=1, reduction_method = reduction_method)
  mobj = orderCells(mobj, num_paths = num_mature_types)
  
  if ( is.null( earliest_day ) ) {
    earliest_day = phenoData(mobj)[["eday"]] %>% as.character %>% as.numeric %>% min
  } 

  # # This code roots the lineage tree using a horrible horrible hack!  
  # # Monocle crashes when you give orderCells a root_state that is an internal node of the ddrtree graph.
  # # I can't tell which f***ing nodes are internal. So I pick the one I want, then rank the states by
  # # their proximity to it in one of the 2d embeddings. I try rooting the tree at the best
  # # ones first, stopping when something works.
  pct_eq_10_5 = function(x) mean( x == earliest_day )
  eday  = phenoData(mobj)[["eday"]] %>% as.character %>% as.numeric
  state = phenoData(mobj)[["State"]] %>% as.character %>% as.numeric
  coords = t( mobj@reducedDimS )
  eday_by_state     = aggregate.nice( x = eday,   by = state, FUN = pct_eq_10_5 )
  centroid_by_state = aggregate.nice( x = coords, by = state, FUN = mean )
  root_state = which.max( eday_by_state ) 
  dist_sq_to_root = apply( centroid_by_state, 1, FUN = function(x) distance_sq(x, centroid_by_state[root_state,]) )
  names( dist_sq_to_root ) = rownames( centroid_by_state )
  dist_sq_to_root = sort( dist_sq_to_root, decreasing = F )
  for( i in seq_along( dist_sq_to_root ) ){
    candidate_state = names( dist_sq_to_root )[[i]]
    e = tryCatch( expr = { mobj = orderCells( mobj, root_state = candidate_state ); e = "success" },
                  error=function( err ){ "failure" } )
    if( e != "failure" ){
      break
    }
  }
  
  
  detach( monocle_params )

  return(mobj)  
}

# # Monocle often returns dozens of cell states.
# # This function simplifies them, compressing everything into the three branches
# # of a "Y" shape.
# # `mobj` is a CellDataSet object.
# # It uses a bunch of heuristics, because if I could do this properly, then I wouldn't need Monocle.
simplify_branches = function( mobj ){
  
  # # Fix the tips at the start of pseudotime, the farthest point from that, and the farthest point from 
  # # those two, where distance to the pair is the minimum over the individual distances.
  root_idx = which.min( mobj@phenoData@data[["Pseudotime"]] )
  root_embedding = mobj@reducedDimS[, root_idx]
  tip1_idx = which.max( apply( X = mobj@reducedDimS, MARGIN = 2, FUN = distance_sq, y = root_embedding ) )
  tip1_embedding = mobj@reducedDimS[, tip1_idx]
  min_dist_sq_other_tips = function(x) {
    d1 = distance_sq( x, tip1_embedding )
    d2 = distance_sq( x, root_embedding )
    return( min( d1, d2 ) )
  }
  tip2_idx = which.max( apply( X = mobj@reducedDimS, MARGIN = 2, FUN = min_dist_sq_other_tips ) )
  tip2_embedding = mobj@reducedDimS[, tip2_idx]
  tips = matrix(NA, ncol = 2, nrow = 3)
  tips[ 1, ] = root_embedding
  tips[ 2, ] = tip1_embedding
  tips[ 3, ] = tip2_embedding
  
  # # For fixed tips and a given center, return the total distance from each point
  # # to the nearest branch, where the branch is a ray terminating at the center and extending
  # # through the branch tip.
  # # Count only three cells per state, randomly selected.
  cells_counted = mobj@phenoData@data %>% rownames
  cells_counted = aggregate.nice( cells_counted, by = mobj@phenoData[["State"]], FUN = sample, size=3)
  cells_counted %<>% c
  get_branchmodel_objective = function( center, return_assignments = F ){
    get_distance_sq_to_branches = function( x ){
      return( c( apply( X = tips, MARGIN = 1, FUN = distance_sq_to_ray, tip2 = center, point = x) ) )
    }
    distances = apply(X = mobj@reducedDimS, MARGIN = 2, FUN = get_distance_sq_to_branches )
    assignments = apply(X = distances, MARGIN = 2, FUN = which.min)
    if( return_assignments ){
      return( assignments )
    }
    
    index_mat = cbind( assignments, 1:ncol(distances))
    index_mat = index_mat[ cells_counted, ]
    return( sum( sqrt( distances[index_mat] ) ) )
  }
  
  # # Place the branchpoint so as to minimize the measure of deviation defined above.
  # # Assign each cell to the nearest branch.
  all_cells = mobj@phenoData@data %>% rownames
  tip_names = all_cells[ c(root_idx, tip1_idx, tip2_idx) ]
  q1 = quantile( mobj@phenoData[["Pseudotime"]], 0.1 )
  q2 = quantile( mobj@phenoData[["Pseudotime"]], 0.9 )
  pt = mobj@phenoData[[ "Pseudotime"]]
  names(pt) = mobj@phenoData@data %>% rownames
  cells_in_middle = all_cells[ q1 < pt[all_cells] & pt[all_cells] < q2 ]
  candidates = sample( setdiff( cells_in_middle, tip_names ), size = 100, replace = F)
  sse_list = apply( X = mobj@reducedDimS[, candidates],
                    MARGIN = 2, 
                    FUN = get_branchmodel_objective )
  branch_point_barcode = names( which.min( sse_list ) )
  branch_point_embedding = mobj@reducedDimS[, branch_point_barcode]
  mobj@phenoData@data[["branch"]] = get_branchmodel_objective( branch_point_embedding, return_assignments = T )[ all_cells ]
  plot_df = data.frame( x = mobj@reducedDimS[1, ],
                        y = mobj@reducedDimS[2, ], 
                        State = as.factor( mobj@phenoData[["State"]] ), 
                        Branch = as.factor( mobj@phenoData[["branch"]] ) )
  
  # # Visual sanity check and return.
  p = ggplot( data = plot_df ) + 
    ggtitle("Simplified branch assignments") +
    geom_point( aes( x = x, y = y, colour = Branch ) ) + 
    geom_line( data = as.data.frame( rbind( branch_point_embedding, tips[1, ] ) ), aes( x = V1, y = V2 ) )  + 
    geom_line( data = as.data.frame( rbind( branch_point_embedding, tips[2, ] ) ), aes( x = V1, y = V2 ) )  + 
    geom_line( data = as.data.frame( rbind( branch_point_embedding, tips[3, ] ) ), aes( x = V1, y = V2 ) )  + 
    geom_point( data = plot_df[mobj@auxOrderingData$DDRTree$branch_points, ],  aes( x = x, y = y ), colour = "purple"  ) 
  print( p )
  return( mobj )
}

# # Calculates the distance between `point` and the closest vector of the form
# # `a( tip1 - tip2 ) + tip2` where a >= 0. 
# # Helper for `simplify_branches`.
# # All inputs should be numeric vectors of the same length.
distance_sq_to_ray = function( tip1, tip2, point ) {
  if( all( tip1 == point ) | all( tip2 == point ) ){ return(0) }
  point_centered = ( point - tip2 )
  tip1_centered  = ( tip1  - tip2 )
  point_centered_scaled  = point_centered / sqrt( distance_sq ( point_centered, 0 ) )
  tip1_centered_scaled   = tip1_centered  / sqrt( distance_sq ( tip1_centered,  0 ) )
  c_cos_theta = sum( tip1_centered_scaled * point_centered_scaled ) * sqrt( distance_sq ( point_centered, 0 ) )
  comp_parallel =  c_cos_theta * tip1_centered_scaled
  if( 0 < c_cos_theta ){
    return ( distance_sq( point_centered, comp_parallel ) )
  } else {
    endpoint_diffs = c( distance_sq ( point, tip2 ), 
                        distance_sq ( point, tip1 ) )
    return ( min ( endpoint_diffs ) )
  }
}

# # This function takes Seurat object and a finished object from a pseudotime analysis package
# # It transfers info from the latter to the former, guaranteeing that the Seurat object
# # will have complete metadata fields of the following names:
# # `pseudotime`, `branch`, `branch_viz_1`, `branch_viz_2`
add_pseudotime_to_seurat = function(dge, pt_obj, pt_method = "monocle" ){
  if( pt_method == "monocle" ){
    to_add = data.frame(
      branch_viz_1 = pt_obj@reducedDimS[1, dge@cell.names], 
      branch_viz_2 = pt_obj@reducedDimS[2, dge@cell.names],
      branch = as.character( pt_obj@phenoData[["State"]] ),
      pseudotime = pt_obj@phenoData[["Pseudotime"]]       ) 
    atae( dge@cell.names,  rownames( pt_obj@phenoData@data ) )
    rownames( to_add ) = dge@cell.names
  } else if (pt_method == "dpt") {
    to_add = data.frame(
      branch_viz_1 = pt_obj@dm@eigenvectors[, 1],
      branch_viz_2 = pt_obj@dm@eigenvectors[, 2],
      branch_viz_3 = pt_obj@dm@eigenvectors[, 3],
      branch = as.character( pt_obj@branch [, 1] ),
      pseudotime = pt_obj[, 1]        )
    to_add$pseudotime = to_add$pseudotime*sign(cor(to_add$pseudotime, FetchData(dge, "eday")))
    rownames( to_add ) = dge@cell.names
    warning("Removing root cell from DPT output due to weird gap from rest of dataset.")
    bad_idx = which( to_add$pseudotime == 0 )
    to_add = to_add[-bad_idx, ]
    dge = Seurat::SubsetData( dge, cells.use = rownames( to_add ) )
  } else {
    warning("Only transfer from monocle and dpt has been implemented. Returning seurat object untouched.")
  }
  dge = Seurat::AddMetaData(dge, to_add)

  return( dge )
}
```

#####Pseudotime helpers

```{r}

# # For bootstrap analysis where I call Monocle on subsets of the data, it's useful to 
# # align all of the results so that cells are in roughly the same positions across bootstrap samples. 
# # This program does that for any two matrices mat_ref and mat_samp.
# # Rows are cells and columns are dimensions of some embedding.
# # They can have different numbers of columns, if you really want, but if the reference has more columns 
# # than the sample you're aligning to it, the resulting matrix will be singular.
# # (If you're a linear algebra nerd, technically this could happen under other circumstances as well, but it's unlikely.)
# #
# # They should have the property `all( rownames( mat_samp ) %in% rownames( mat_ref ) )`, or
# # else they should have the same number of rows.
# #
# # The return value is a projection of each column of mat_ref onto the column space of the 
# # augmented matrix [mat_samp | 1]. In other terms, mat_samp is translated and linearly transformed to 
# # minimize the l2 distance to mat_ref.
# # This function always returns a numeric matrix with ncol = ncol(mat_ref) and nrow = nrow(mat_samp).
align_embedding_to_reference = function(mat_samp, mat_ref, do.plot = F){
  
  # # Handle vectors
  if( is.null( dim ( mat_samp ) ) ) { mat_samp = matrixify_preserving_rownames( mat_samp ) }
  if( is.null( dim ( mat_ref  ) ) ) { mat_ref  = matrixify_preserving_rownames( mat_ref  ) }
  
  # # Handle dataframes
  mat_samp = as.matrix( mat_samp )
  mat_ref  = as.matrix( mat_ref  )

  # # Check dimensions
  if( ncol( mat_samp ) > nrow( mat_samp ) ||
      ncol( mat_ref  ) > nrow( mat_ref  ) ){
    warning("Did you forget to transpose?")
  }
  
  # # Ensure rownames present and compatible between sample and reference
  if( is.null( rownames( mat_samp ) ) |  is.null( rownames( mat_ref ) ) ){
    if( nrow( mat_samp ) != nrow( mat_ref ) ){ 
      stop( "Either number of rows should be equal or rows should be named with `all( rownames( mat_samp ) %in% rownames( mat_ref ) )`." ) 
    } else {
      rownames( mat_samp ) = as.character( 1:nrow( mat_samp ) )
      rownames( mat_ref )  = as.character( 1:nrow( mat_samp ) )
    }
  }
  atat( !is.null( rownames( mat_samp ) ) )
  atat( !is.null( rownames( mat_ref  ) ) )
  atat( all( rownames( mat_samp ) %in% rownames( mat_ref ) ) )
  mat_ref = mat_ref[ rownames( mat_samp ) , , drop = F] # drop = F GODDAMMIT

  # # Do math
  mat_return = matrix( lm( mat_ref ~ mat_samp )$fitted.values, ncol = ncol( mat_ref ) )
  
  # # guarantee nice named-matrix output
  rownames( mat_return ) = rownames( mat_samp ) 
  atat( nrow( mat_return ) == nrow( mat_samp ) )
  atat( ncol( mat_return ) == ncol( mat_ref ) )
  atat( is.numeric( mat_return ) )
  
  # # For testing
  if(do.plot){
    mat_ref     = data.frame( mat_ref );    mat_ref$type    = "input_ref"
    mat_samp    = data.frame( mat_samp );   mat_samp$type   = "input_sample"
    mat_return  = data.frame( mat_return ); mat_return$type = "return_val"
    df_all = rbind( mat_ref, mat_samp, mat_return )
    p = ggplot(df_all) + ggtitle("return_val and input_ref should be aligned") +
      geom_point(aes(X1, X2, colour = type), alpha = 0.2)
    print(p)
  } 
  return( mat_return )
}

# # Brief test script
# # One dimensional test
# refscale = 1:5; names(refscale) = letters[1:5]
# atae( matrixify_preserving_rownames( refscale ), 
#       align_embedding_to_reference(mat_ref = refscale, mat_samp = -10*refscale + 4 ),
#       tolerance = 0.000001,
#       check.attributes = F)
# # # Two dimensional test
# noisy_l  = cbind(-99:100, c( rep(1, 100), 1:100 ) - 50 ) + matrix( 2*rnorm(400), ncol = 2 )
# rownames( noisy_l ) = make.unique( letters[(1:200 %% 25) + 1] )
# noisy_l_rot = noisy_l %*% matrix( c(1, 1, -1, 1), nrow = 2 ) + matrix( 2*rnorm(400), ncol = 2 )
# tmp = align_embedding_to_reference(mat_ref  = noisy_l,
#                                    mat_samp = noisy_l, 
#                                    do.plot = T)
# tmp = align_embedding_to_reference(mat_ref  = noisy_l,
#                                    mat_samp = noisy_l_rot, 
#                                    do.plot = T)

```
